{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d53b7f06",
   "metadata": {},
   "source": [
    "# Part A: Introduction to OpenCV and Template Matching\n",
    "\n",
    "In the first part we will start by familiarizing with the OpenCV matctTemplate tools. \n",
    "1. We will start by operating only on the left frame of the stereo image pair. Our goal is to select a template, that is a small crop of the image, and by using the cv2.matchTemplate tool, to locate this crop on the original image. By visualizing the distance heat-map and a rectangle over the prediction we can evaluate the results of the algorithm. \n",
    "2. We will repeat the same process of the right frame of the stereo pair. \n",
    "3. Is there a way to eliminate the range of rows that we should parse to find a match? We know that both cameras are on the came level. \n",
    "4. Are there any other ways to narrow down the search area. \n",
    "5. Calculate the disparity value between the 2 frams for the template patch. \n",
    "\n",
    "To define the template patch we need the starting row and column as well as the block size. We consider the template to be square. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9d9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Section\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import utility as U\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from math import tan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04375c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"sample_data/left.ppm\", cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "print(\"Image Shape: \", img.shape)\n",
    "\n",
    "template_row_start = 165\n",
    "template_col_start = 135\n",
    "block_size = 50\n",
    "\n",
    "# TODO\n",
    "template = img[template_row_start:template_row_start+block_size, template_col_start:template_col_start+block_size]\n",
    "print(\"Template Shape: \", template.shape)\n",
    "plt.imshow(template, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e1d1b4a",
   "metadata": {},
   "source": [
    "Use the template matching to locate the template in the image. We need to define a distance function that will do this. In this example we will use the square distance. You could experiment with different distance functions.  \n",
    "\n",
    "The result of the matchTemplate should be a headmap of the distance for each patch in the image. We define a patch by the top-left point. Notice that the shape of the heat_map is smaller that the original image.\n",
    "\n",
    "To find the patch we need to locate the point with the smallest distance. To do so we can use the cv2.minMacLoc method. \n",
    "\n",
    "For this cell we will use a custom function to visualize the rectangle. Notice the order of the arguments when we call the Rectangle constructor. In later cells we will the *disp_image_and_rectangle* from the utility.py. \n",
    "Just use *U.disp_image_and_rectangle(img, rect_start, template_rows, template_cols)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24731b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cv2.matchTemplate(img, template, cv2.TM_SQDIFF_NORMED)\n",
    "\n",
    "print(\"Heat-map shape: \", res.shape)\n",
    "plt.imshow(res)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# find the location of the min value\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "\n",
    "## Visualize the rectangle ##\n",
    "# Get the shape of the template\n",
    "rows, cols = template.shape\n",
    "\n",
    "# Display the original image\n",
    "plt.imshow(img, cmap='gray')\n",
    "\n",
    "# Get the current reference\n",
    "ax = plt.gca()\n",
    "\n",
    "# Create a Rectangle patch\n",
    "rect = Rectangle(min_loc, cols, rows, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "# Add the patch to the Axes\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5e13eeb",
   "metadata": {},
   "source": [
    "## Now try to locate the template in the right frame\n",
    "\n",
    "By using the *visualize_stereo_frames* from utility.py we can visualize the two frames next to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1058ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "right_img = cv2.imread(\"sample_data/right.ppm\", cv2.IMREAD_GRAYSCALE)\n",
    "U.visualize_stereo_frames(img, right_img)\n",
    "\n",
    "# Do the template matching\n",
    "res = cv2.matchTemplate(right_img, template, cv2.TM_SQDIFF)\n",
    "\n",
    "# Get the minimum distance position\n",
    "_, _, min_loc_right, _ = cv2.minMaxLoc(res)\n",
    "\n",
    "# Visualize the rectangle\n",
    "U.disp_image_and_rectangle(right_img, min_loc_right, rows, cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76a2a1ad",
   "metadata": {},
   "source": [
    "### Print the row that the template was found on, in the right frame. What do you observe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa1735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Row of the template in the left image : \", template_row_start)\n",
    "print(\"Row of the template in the right image : \", min_loc_right[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee7d9b1e",
   "metadata": {},
   "source": [
    "### Narrow down the Region of Interest (RoI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade571d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 1.3: Search for the template only in the same row of the second image,\n",
    "#           since the cameras are on the same level \n",
    "# a. Crop the second image and only keep the row that contains the \n",
    "right_img_crop = right_img[template_row_start:template_row_start+block_size, :]\n",
    "plt.imshow(right_img_crop, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "# Do the template matching\n",
    "res = cv2.matchTemplate(right_img_crop, template, cv2.TM_SQDIFF)\n",
    "# Get the minimum distance position\n",
    "_, _, min_loc_right_crop, _ = cv2.minMaxLoc(res)\n",
    "# Visualize the rectangle\n",
    "U.disp_image_and_rectangle(right_img_crop, min_loc_right_crop, rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 1.4: Narrow the search even more\n",
    "# Since we use the right frame, the template with be to the left, \n",
    "# comparing to the original position in the left image.\n",
    "\n",
    "# Make a new crop of the image (should contain the coordinates of the template)\n",
    "right_img_crop_crop = right_img[template_row_start:template_row_start+block_size, :template_col_start+block_size]\n",
    "plt.imshow(right_img_crop_crop, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Do the template matching\n",
    "res = cv2.matchTemplate(right_img_crop_crop, template, cv2.TM_SQDIFF)\n",
    "# Get the minimum distance position\n",
    "_, _, min_loc_right_crop_crop, _ = cv2.minMaxLoc(res)\n",
    "# Visualize the rectangle\n",
    "U.disp_image_and_rectangle(right_img_crop_crop, min_loc_right_crop_crop, rows, cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12414c1a",
   "metadata": {},
   "source": [
    "## Disparity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity = template_col_start - min_loc_right_crop_crop[0]\n",
    "print(f\"The disparity value is {disparity}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f57346e",
   "metadata": {},
   "source": [
    "# Part B: Disparity extraction from stereo images\n",
    "\n",
    "In order to calculate the disparity we need to repeat the same process that we followed for the template but for each pixel of the left image, except for the marginal pixels (right and bottom rows) that their template would be out the image frame. \n",
    "\n",
    "In order to start clean in the next cell we reload and visualize the stereo image frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01628bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting paths\n",
    "datapath = \"./sample_data/\"\n",
    "left_frame_path = datapath + \"left.ppm\"\n",
    "right_frame_path = datapath + \"right.ppm\"\n",
    "disparity_path = datapath + \"truedisp.pgm\"\n",
    "\n",
    "\n",
    "# Loading the two frames again (both greyscale -> disparity and color version -> visualization)\n",
    "left_frame = cv2.imread(left_frame_path, cv2.IMREAD_GRAYSCALE)\n",
    "left_frame_color = cv2.imread(left_frame_path)\n",
    "right_frame = cv2.imread(right_frame_path, cv2.IMREAD_GRAYSCALE)\n",
    "right_frame_color = cv2.imread(right_frame_path)\n",
    "\n",
    "U.visualize_stereo_frames(left_frame, right_frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4f8b5e7",
   "metadata": {},
   "source": [
    "## Disparity_map\n",
    "\n",
    "*NOTE: Only search the left most pixels that the current pixel to find the disparity.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb390cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the block size\n",
    "block_size = 8\n",
    "\n",
    "\n",
    "frame_shape = left_frame.shape # [288, 384]\n",
    "\n",
    "# Create an image to store the disparity\n",
    "disparity_map = np.zeros_like(left_frame)\n",
    "\n",
    "\n",
    "# Parse the pixels - Use tqdm to monitor the process. \n",
    "for i in tqdm(range(frame_shape[0] - block_size)):\n",
    "    \n",
    "    for j in range(frame_shape[1] - block_size):\n",
    "        \n",
    "        # get the tamplate form the left frame\n",
    "        template = left_frame[i:i+block_size, j:j+block_size]\n",
    "\n",
    "        # get the crop/roi from the right frame\n",
    "        # roi -> region of interest\n",
    "        roi = right_frame[i:i+block_size,0:j+block_size]\n",
    "\n",
    "        # do the block matching\n",
    "        res = cv2.matchTemplate(roi, template, cv2.TM_SQDIFF)\n",
    "\n",
    "        # locate the coordiante od the best match\n",
    "        _, _, loc_min, _ = cv2.minMaxLoc(res)\n",
    "\n",
    "        # calculate the disparity value (should be positive)\n",
    "        # loc_min[0] -> the first element in column\n",
    "        disparity = j - loc_min[0]\n",
    "\n",
    "        # Save the disparity value in the map\n",
    "        disparity_map[i, j] = disparity\n",
    "\n",
    "\n",
    "plt.imshow(disparity_map)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "207e5739",
   "metadata": {},
   "source": [
    "## Disparity map with more contrains \n",
    "\n",
    "We set a new hyper-parameter that is the maximum number of blocks that should search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089989e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image to store the disparity\n",
    "disparity_map = np.zeros_like(left_frame)\n",
    "max_num_blocks = 5\n",
    "\n",
    "# Parse the pixels\n",
    "for i in tqdm(range(frame_shape[0] - block_size)):\n",
    "    for j in range(frame_shape[1] - block_size):\n",
    "        \n",
    "        template = left_frame[i:i+block_size, j:j+block_size]\n",
    "\n",
    "        start = max(0,j - max_num_blocks * block_size)\n",
    "        end = j+block_size\n",
    "        \n",
    "        roi = right_frame[i: i + block_size, start : end]\n",
    "\n",
    "        res = cv2.matchTemplate(roi, template, cv2.TM_SQDIFF)\n",
    "\n",
    "        _, _, min_loc, _ = cv2.minMaxLoc(res)\n",
    "\n",
    "        disparity = j - (min_loc[0] + start)\n",
    "\n",
    "        disparity_map[i, j] = disparity\n",
    "\n",
    "\n",
    "plt.imshow(disparity_map)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e141a5f",
   "metadata": {},
   "source": [
    "## Use OpenCV BlockMatching to calculate the disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee8d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to define a new hyper-parameter that is the number of disparities\n",
    "# This number has to be a multiple of 16 and the block_size must be an odd number\n",
    "block_size = 9\n",
    "num_disparities = 5 * 16\n",
    "\n",
    "\n",
    "stereo = cv2.StereoBM_create(numDisparities=num_disparities, blockSize=block_size)\n",
    "cv_disparity = stereo.compute(left_frame, right_frame)\n",
    "plt.imshow(cv_disparity)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "461904b4",
   "metadata": {},
   "source": [
    "## Load and visualize the ground truth disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_disparity = cv2.imread(disparity_path)[..., 0]\n",
    "plt.imshow(true_disparity)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b67cc1ac",
   "metadata": {},
   "source": [
    "# Part C: Point Cloud reconstruction from disparity map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disparity_map = true_disparity\n",
    "\n",
    "rows, columns = disparity_map.shape[0], disparity_map.shape[1]\n",
    "\n",
    "# finding the center of the image\n",
    "u0 = columns / 2 \n",
    "v0 = rows / 2\n",
    "\n",
    "# Constant parameters, depending on the camera parameters and position\n",
    "stereo_baseline = 0.2\n",
    "fieldOfView = 1.2\n",
    "focal_length_constant = 1.0 / (2.0 * tan(fieldOfView / 2.0))\n",
    "\n",
    "print(\"focal_length_constant: \", focal_length_constant)\n",
    "print(\"stereo_baseline: \", stereo_baseline)\n",
    "\n",
    "vertices = []\n",
    "colors = []\n",
    "\n",
    "for i in range(columns):\n",
    "    for j in range(rows):\n",
    "        \n",
    "        d = disparity_map[j][i] / columns\n",
    "        color = left_frame_color[j,i]\n",
    "\n",
    "        if d==0:\n",
    "            continue\n",
    "        else:\n",
    "            z = focal_length_constant * (stereo_baseline / d)\n",
    "            x = ((i-u0) / columns) * (z / focal_length_constant)\n",
    "            y = - ((j-v0) / rows) * (z / focal_length_constant)\n",
    "            \n",
    "            if z>0:\n",
    "                vertices.append(np.array([40*x,40*y,-40*z]))\n",
    "                colors.append(np.array(color / 255.0))\n",
    "\n",
    "\n",
    "\n",
    "vertices = np.stack(vertices)\n",
    "colors = np.stack(colors)\n",
    "\n",
    "# U.visualize_point_cloud(vertices, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ebdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "labels = DBSCAN(5,min_samples=50).fit(vertices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76409cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = vertices[labels > -1]\n",
    "colors = colors[labels>-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3c8f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "U.visualize_point_cloud(vertices, colors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
